from vllm/vllm-openai:v0.9.1

RUN pip3 install flash_attn==2.8.0.post2
RUN pip3 install transformers==4.51.3